{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is an attemp to better understand (through implementation) the working and details of RNN implementations. We have used pytorch as a library of choice for building the RNN, but the described methods can be used with other deep learning libraries. \n",
    "\n",
    "**Note** that the code proviede here should only be used for practicing and understanding of the matter at hand. The offered implementation here is almost an order of magnitude slower than the one from the pytorch library. \n",
    "\n",
    "We heavily rely on definitions, notations and documentations from [Deep Learning](https://www.deeplearningbook.org/) book (Chp. 10) and [pytorch](https://pytorch.org/docs/stable/nn.html#rnn) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notation and definition of RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/rnn1.png\" style=\"float: left; width: 700px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notation__: The left and right of the arrow correspond to variables in domain and co-domain of the function. The object on top of the arrow represent the function that acts on the domain variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/rnn2.png\" style=\"float: left; width: 250px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notation__: aggregate of two variables is shown as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/rnn3.png\" style=\"float: left; width: 200px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting these together, we can represent the flow of information in a RNN cell as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/rnn4.png\" style=\"float: left; width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanded RNNs of one layer and two layer with sequence length of 3 is shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/rnn5.png\" style=\"float: left; width: 700px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to do the forward pass in a multilayer RNN is to compute one layer at a time, as is shown in the following 2-layer example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/animated_gif_1.gif\" style=\"float: left; width: 700px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we need the initial values for the hidden variables of each layer ($h_0$ and $g_0$) to start the forward pass in that layer. Another thing to notice is that for multi-layer RNNs, the hidden variables of the lower layers act as inputs for updating the hidden variables of the layer top, the same way that $x_i$s are used for computing of the hidden variables of the first layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "We implement a subset of what is implemented in pytorch:\n",
    "- Only uni-directional RNN is implemented \n",
    "- We only implement the `batch_first = True` variation. \n",
    "- Only `tanh` activation is considered (in pytorch one can choose between `tanh` and `relu`).\n",
    "- For automatic differentiation pytorch's `autograd` module is used. We only care about the soundness of forward pass in our implementation and delegate the differentiation to pytorch.\n",
    "\n",
    "We use the same variable namings of parameters for compatibility with pytorch `nn.RNN` class. The `__init__` method is largely based (and copied) from pytorch. The forward method, which is the main point of this implementaion, is written form scratch. The initialization of the the object, input and output of the forward pass are all compatible with `nn.RNN` (in `batch_first=True` mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch import tensor, stack\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    '''An RNN class based on pytorch implementation.'''\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # We name the variables identical to their counter parts in\n",
    "        # pytorch. Please refer to pytorch source code for more\n",
    "        self.ws_ih = []\n",
    "        self.ws_hh = []\n",
    "        self.bs_ih = []\n",
    "        self.bs_hh = []\n",
    "        for layer in range(num_layers):\n",
    "            layer_input_size = input_size if layer == 0 else hidden_size\n",
    "            w_ih = self._init_weight_((hidden_size, layer_input_size,))\n",
    "            w_hh = self._init_weight_((hidden_size, hidden_size,))\n",
    "            b_ih = self._init_weight_((hidden_size,))\n",
    "            b_hh = self._init_weight_((hidden_size,))\n",
    "            \n",
    "            param_names = ['weight_ih_l{}', 'weight_hh_l{}',\n",
    "                           'bias_ih_l{}', 'bias_hh_l{}']\n",
    "            param_names = [name.format(layer) for name in param_names]\n",
    "            layer_params = (w_ih, w_hh, b_ih, b_hh)\n",
    "            \n",
    "            for param, name in zip(layer_params, param_names):\n",
    "                setattr(self, name, param)\n",
    "            self.ws_ih.append(w_ih)\n",
    "            self.ws_hh.append(w_hh)\n",
    "            self.bs_ih.append(b_ih)\n",
    "            self.bs_hh.append(b_hh)\n",
    "                \n",
    "        \n",
    "    def _init_weight_(self, shape):\n",
    "        k_sqrt = torch.sqrt(torch.tensor(1/self.hidden_size))\n",
    "        weight = 2.0 * k_sqrt * torch.rand(shape) - k_sqrt\n",
    "        return nn.Parameter(weight)\n",
    "    \n",
    "    \n",
    "    def batch_forward(self, x, h_0):\n",
    "        return self.layers_forward(self.tanh_cell, x, h_0)\n",
    "                \n",
    "    def cum_map(self, f, xs, h):\n",
    "        # f, [x_1,x_2, ..., x_L], h_0 => [h_1=f(x_1, h_0), h_2=f(x_2, h_1), ..., h_L=f(x_L, h_{L-1})], h_L\n",
    "        cum_results = []\n",
    "        for x in xs:\n",
    "            h = f(x, h)\n",
    "            cum_results.append(h)\n",
    "        return torch.stack(cum_results), h\n",
    "    \n",
    "    def tanh_cell(self, x, h, w_ih, w_hh, b_ih, b_hh):\n",
    "        return torch.tanh(\n",
    "            torch.einsum('ij,j', w_ih, x) + torch.einsum('ij,j', w_hh, h) + \\\n",
    "            b_ih + b_hh\n",
    "        )\n",
    "    \n",
    "    def layers_forward(self, f, x, h_inits):\n",
    "        '''forward pass in each layer\n",
    "        returns last layers hidden variables and last hidden variable of each layer\n",
    "        '''\n",
    "        hs_L = []\n",
    "        for i_layer, h_0 in enumerate(h_inits):\n",
    "            f_partial = partial(f, w_ih=self.ws_ih[i_layer],\n",
    "                                   w_hh=self.ws_hh[i_layer],\n",
    "                                   b_ih=self.bs_ih[i_layer],\n",
    "                                   b_hh=self.bs_hh[i_layer])\n",
    "            x, h_L = self.cum_map(f_partial, x, h_0)\n",
    "            hs_L.append(h_L)\n",
    "        return x, torch.stack(hs_L)                \n",
    "\n",
    "    def __call__(self, x, h_0=None):\n",
    "        '''inputs   x:   [N, L, H_in]\n",
    "                    h_0: [N, num_layers, H_out]\n",
    "           outputs  h:   [N, L, H_out]\n",
    "                    h_L  [N_layer, N, H_out]\n",
    "        '''\n",
    "        if h_0 is None:\n",
    "            h_0 = torch.zeros(self.num_layers, N, self.hidden_size)\n",
    "        h_0 = h_0.reshape(N, self.num_layers, self.hidden_size)\n",
    "        \n",
    "        batch_hs = []  # h sequence           [L, H_out]\n",
    "        batch_hn = []  # last h in each layer [N_layer, H_out]\n",
    "        # loop on each batch \n",
    "        for x_batch, h_0_batch in zip(x, h_0):\n",
    "            hs, hn = self.batch_forward(x_batch, h_0_batch)\n",
    "            batch_hs.append(hs)\n",
    "            batch_hn.append(hn)\n",
    "        return torch.stack(batch_hs), \\\n",
    "               torch.einsum('ijk->jik', torch.stack(batch_hn))  # N, N_layer, H_out -> N_layer, N, H_out\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2              # batch size\n",
    "h_in = 2           # dimension of input vectors x_i\n",
    "h_out = 5          # dimension of hidden variables h_i\n",
    "num_layers = 3     # \n",
    "L = 100            # length of input sequence (x_1, ... x_L)\n",
    "\n",
    "\n",
    "rnn_torch = nn.RNN(input_size=h_in, hidden_size=h_out, num_layers=num_layers, batch_first=True)\n",
    "rnn_me = RNN(input_size=h_in, hidden_size=h_out, num_layers=num_layers)\n",
    "\n",
    "x = torch.rand(N, L, h_in)                 # [N, L, h_in]\n",
    "h_0 = torch.rand(num_layers, N, h_out)     # [num_layers, N, h_out]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we copy all the parameters (weights and biases) from the torch rnn to the one we just made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "params = ['bias_ih_l', 'bias_hh_l', 'weight_ih_l', 'weight_hh_l']\n",
    "for param, layer in product(params, [str(i) for i in range(num_layers)]):\n",
    "    param_me = getattr(rnn_me, param+layer)\n",
    "    param_torch = getattr(rnn_torch, param+layer)\n",
    "    param_me.data = param_torch.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_torch, hs_torch_n = rnn_torch(x)\n",
    "hs_slow, hs_slow_n = rnn_me(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the results visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1588, -0.6647, -0.2076,  0.2584,  0.5815],\n",
      "        [-0.0107, -0.8001,  0.0806, -0.2116,  0.3661],\n",
      "        [-0.0609, -0.7705,  0.2482, -0.0761,  0.3675],\n",
      "        [-0.0202, -0.7911,  0.2288,  0.0182,  0.3550],\n",
      "        [-0.1055, -0.8029,  0.2264,  0.0278,  0.4159],\n",
      "        [-0.0102, -0.8006,  0.2319,  0.0255,  0.3760],\n",
      "        [-0.0800, -0.8151,  0.2640, -0.0154,  0.4040],\n",
      "        [-0.1028, -0.7923,  0.2608,  0.1169,  0.4254],\n",
      "        [-0.0493, -0.8170,  0.2063, -0.0154,  0.3472],\n",
      "        [-0.0312, -0.7947,  0.2332,  0.0149,  0.4130]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-0.1588, -0.6647, -0.2076,  0.2584,  0.5815],\n",
      "        [-0.0107, -0.8001,  0.0806, -0.2116,  0.3661],\n",
      "        [-0.0609, -0.7705,  0.2482, -0.0761,  0.3675],\n",
      "        [-0.0202, -0.7911,  0.2288,  0.0182,  0.3550],\n",
      "        [-0.1055, -0.8029,  0.2264,  0.0278,  0.4159],\n",
      "        [-0.0102, -0.8006,  0.2319,  0.0255,  0.3760],\n",
      "        [-0.0800, -0.8151,  0.2640, -0.0154,  0.4040],\n",
      "        [-0.1028, -0.7923,  0.2608,  0.1169,  0.4254],\n",
      "        [-0.0493, -0.8170,  0.2063, -0.0154,  0.3472],\n",
      "        [-0.0312, -0.7947,  0.2332,  0.0149,  0.4130]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(hs_torch[0, 0:10, :])\n",
    "print(hs_slow[0, 0:10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use the `norm` function for a quantitative difference of the two tensors: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7207e-07, grad_fn=<NormBackward0>)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_diff = lambda x, y: torch.norm(x/torch.norm(x) - y/torch.norm(y))\n",
    "norm_diff(hs_torch, hs_slow)\n",
    "# torch.norm(hs_torch/torch.norm(hs_torch) - hs_slow/torch.norm(hs_slow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is negligible compared to the size of two tensors' entries.\n",
    "\n",
    "To make sure that our implementation is according to the specification, we have to make sure that our the produced computatioanl graph for outputs are comparable to the one from pytorch. This is a hard problem with what I know of. In a sense one has to show that both graphs are, loosely speaking, **equivalent** to the canonical representation of the graph of the tensor. We may, however, seek to show that the gradients computed with `.backward` method are close enough to each other for a given function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_torch, hs_torch_n = rnn_torch(x)\n",
    "hs_slow, hs_slow_n = rnn_me(x)\n",
    "\n",
    "# define a functional from output of both RNNs\n",
    "l = torch.norm(torch.sum(hs_torch, dim=1))\n",
    "rnn_torch.zero_grad()\n",
    "l.backward()\n",
    "\n",
    "l = torch.norm(torch.sum(hs_slow, dim=1))\n",
    "rnn_me.zero_grad()\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we loop over all the parameters of two model and compute the norm of the difference of their gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4588e-06)\n"
     ]
    }
   ],
   "source": [
    "sum_norm_diff = 0.0\n",
    "for param_me, param_torch in zip(rnn_me.parameters(), rnn_torch.parameters()):\n",
    "    sum_norm_diff += norm_diff(param_me.grad, param_torch.grad)\n",
    "print(sum_norm_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which shows again a very good agreement between the two implementations, given that the used functional is by no means trivial ($l=\\lVert \\Sigma_{i}  h_i\\rVert$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timing of the two implementations shows pytorch is 4 to 8 times faster than our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 ms ± 766 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hs, hs_n = rnn_me(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.6 ms ± 84.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hs, hs_n = rnn_torch(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
